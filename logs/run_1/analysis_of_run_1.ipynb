{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook should help with the analysis of the results from the first application of the correction of values.\n",
    "The research question is "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is there a correlation between degradation and overshooting of predictions?\n",
    "- Should the restricted area be calculated using the truth@t-1 and truth@t-2 instead of truth@t-1 and pred@t-1?\n",
    "- Should the restricted area be depending on the length of 1s/0s on the prediction?\n",
    "- How is the degradation distributed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How big is the influence of the correction if the restriction is too big?\n",
    "- How to calculate beta and parts of the correction?\n",
    "- How to consider dimension jumps in the correction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading log files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in the data from the log files as pandas panel objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"Delta2PowerTwo\",\"PreviousError\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename, methodshorthand):\n",
    "    if methodshorthand == \"prer\":\n",
    "        with open(filename, 'r') as f:\n",
    "            file_str = [line.split(',', 1)[1] for line in f.readlines() if \",\" in line and \"offset\" not in line]\n",
    "            file_str = StringIO(\"\".join(file_str))\n",
    "            df = pd.read_csv(file_str, index_col=0, header=None)\n",
    "            df.columns = [\"uncorrected\", \"corrected\", \"truth\", \"overshot\", \"offset\", \"empty\"]\n",
    "            df.index.name = \"index\"\n",
    "        return df\n",
    "    elif methodshorthand == \"d2p2\":\n",
    "        with open(filename, 'r') as f:\n",
    "            file_str = [line.split(',', 1)[1] for line in f.readlines() if \",\" in line and \"restricted\" not in line]\n",
    "            file_str = StringIO(\"\".join(file_str))\n",
    "            df = pd.read_csv(file_str, index_col=0, header=None)\n",
    "            df.columns = [\"uncorrected\", \"corrected\", \"truth\", \"overshot\", \"restricted\", \"delta\"]\n",
    "            df.index.name = \"index\"\n",
    "        return df\n",
    "\n",
    "def get_panel(method):\n",
    "    handles = dict(PreviousError=\"prer\", Delta2PowerTwo=\"d2p2\")\n",
    "    shorthand = handles[method]\n",
    "    logfiles =  './*{}.log'.format(shorthand)\n",
    "    logfiles = sorted(glob(logfiles))\n",
    "    return pd.Panel({fname:read_file(fname, shorthand) for fname in logfiles})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual processing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lzc(val, bits=32):\n",
    "    \"\"\"Count leading zeroes.\"\"\"\n",
    "    cnt = 0\n",
    "    for i in range(0, bits):\n",
    "        if val & (1 << (bits - 1 - i)) != 0:\n",
    "            break\n",
    "        cnt += 1\n",
    "    return cnt\n",
    "lzcu = np.frompyfunc(lzc, 2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation of overshooting and performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def calculate_performance_correlation_with_overshooting(filename, panel):\n",
    "    uncorrected_residual = np.bitwise_xor(panel[filename,:,:]['uncorrected'], panel[filename,:,:]['truth'])\n",
    "    corrected_residual = np.bitwise_xor(panel[filename,:,:]['corrected'], panel[filename,:,:]['truth'])\n",
    "    better_cases = lzcu(corrected_residual, 32) > lzcu(uncorrected_residual, 32)\n",
    "    same_cases = lzcu(corrected_residual, 32) == lzcu(uncorrected_residual, 32)\n",
    "    worse_cases = lzcu(corrected_residual, 32) < lzcu(uncorrected_residual, 32)\n",
    "    overshooting = panel[filename,:,\"overshot\"]\n",
    "    b_correlation = np.corrcoef(overshooting.astype(bool), better_cases.astype(bool))[0,1]\n",
    "    s_correlation = np.corrcoef(overshooting.astype(bool), same_cases.astype(bool))[0,1]\n",
    "    w_correlation = np.corrcoef(overshooting.astype(bool), worse_cases.astype(bool))[0,1]\n",
    "    \n",
    "    correlation_performance_overshooting = namedtuple(\"CPOS\", \"fname,better,worse,same,bcorr,wcorr,scorr\")\n",
    "    return correlation_performance_overshooting(filename,better_cases.sum(),worse_cases.sum(),same_cases.sum(),\n",
    "                                                b_correlation,w_correlation, s_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "threshold = .1\n",
    "for m in methods:\n",
    "    panel = get_panel(m)\n",
    "    all_performances = [calculate_performance_correlation_with_overshooting(x, panel) for x in panel.items]\n",
    "    print(m)\n",
    "    significant = [print(\"{:60} {:+.2f} {:+.2f} {:+.2f}     {} {} {}\".format(x.fname,x.bcorr,x.wcorr,x.scorr,\n",
    "                                                                        abs(x.bcorr)  > threshold,abs(x.wcorr)  > threshold,abs(x.scorr) > threshold)) \n",
    "                   if not np.isnan(x.bcorr) else \n",
    "                   print(\"{:60}\".format(x.fname)) \n",
    "                   for x in all_performances]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the correction an actual improvement of the prediction (which simply is not represented in the LZC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filename = './icon.pl.qv.f32.little.4x47x351x901_2.prer.log'\n",
    "\n",
    "def calculate_absolute_performance(filename, panel):\n",
    "    corrected_diff = (panel[filename, :, \"corrected\"] - panel[filename, :, \"truth\"]).abs()\n",
    "    uncorrected_diff = (panel[filename, :, \"uncorrected\"] - panel[filename, :, \"truth\"]).abs()\n",
    "    better_cases = corrected_diff < uncorrected_diff\n",
    "    same_cases = corrected_diff == uncorrected_diff\n",
    "    worse_cases = corrected_diff > uncorrected_diff\n",
    "    \n",
    "    correlation_performance_overshooting = namedtuple(\"CAP\", \"fname,better,worse,same\")\n",
    "    return correlation_performance_overshooting(filename,better_cases.mean(),worse_cases.mean(),same_cases.mean())\n",
    "\n",
    "for m in methods:\n",
    "    panel = get_panel(m)\n",
    "    all_performances = [calculate_absolute_performance(x, panel) for x in panel.items]\n",
    "    print(m)\n",
    "    print(\"{:60} {:>4} {:>4} {:>4}      better  not worse\".format(\"file\",\"b\",\"w\",\"s\"))\n",
    "    significant = [print(\"{:60} {:03.2f} {:03.2f} {:03.2f}     {:>6}  {:>6}\".format(x.fname,x.better,x.worse,x.same,str(x.better >= .5),str(x.better+x.same >= .5))) for x in all_performances]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the \"average\" range of LZCs back to back of each other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ninties = np.zeros(panel.items.size)\n",
    "nintyfives = np.zeros(panel.items.size)\n",
    "nintynines = np.zeros(panel.items.size)\n",
    "\n",
    "for m in methods:\n",
    "    panel = get_panel(m)\n",
    "    print(m)\n",
    "    for i,item in enumerate(panel.items):\n",
    "        df = panel.loc[item,:,:][[\"uncorrected\",\"corrected\",\"truth\"]].astype(\"int\")\n",
    "        df[\"uncorrected_residue\"] = df[\"truth\"] ^ df[\"uncorrected\"]\n",
    "        df[\"uncorrected_lzc\"] = lzcu(df[\"uncorrected_residue\"], 32)\n",
    "        ninety = np.percentile(df[\"uncorrected_lzc\"].diff().abs(), 90)\n",
    "        ninetyfive = np.percentile(df[\"uncorrected_lzc\"].diff().abs(), 95)\n",
    "        ninetynine = np.percentile(df[\"uncorrected_lzc\"].diff().abs(), 99)\n",
    "        ninties[i] = ninety\n",
    "        nintyfives[i] = ninetyfive\n",
    "        nintynines[i] = ninetynine\n",
    "        print(\"{:60} {:5.2f} {:5.2f} {:5.2f}\".format(item, ninety, ninetyfive, ninetynine))\n",
    "pd.Series(nintynines).plot.line(label='99%')\n",
    "pd.Series(nintyfives).plot.line(label='95%')\n",
    "pd.Series(ninties).plot.line(label='90%')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(ninties).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is there a correlation of the back-to-back fluctuation of LZC and the length of MS1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ms1(num):\n",
    "    summation = 0\n",
    "    lz = lzc(num)\n",
    "    try:\n",
    "        while 1 << 32 - lz - 1 - summation & num > 0:\n",
    "            summation += 1\n",
    "    except ValueError as e:\n",
    "        if \"negative shift count\" in str(e):\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "    return summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for m in methods:\n",
    "    panel = get_panel(m)\n",
    "    print(m)\n",
    "    for i,item in enumerate(panel.items):\n",
    "        df = panel.loc[item,:,:][[\"uncorrected\",\"corrected\",\"truth\"]].astype(\"int\")\n",
    "        df[\"uncorrected_residue\"] = df[\"truth\"] ^ df[\"uncorrected\"]\n",
    "        df[\"uncorrected_lzc\"] = lzcu(df[\"uncorrected_residue\"], 32)\n",
    "        df[\"ms1\"] = [ms1(x) for x in df[\"uncorrected_residue\"]]\n",
    "        corr_lzcdiff_ms1 = np.corrcoef(df[\"uncorrected_lzc\"].astype(\"int\").diff().abs()[1:], df[\"ms1\"].astype(\"int\")[:-1])[0,1]\n",
    "        corr_residue_ms1 = np.corrcoef(df[\"uncorrected_residue\"].astype(\"int\"), df[\"ms1\"].astype(\"int\"))[0,1]\n",
    "        corr_lzcdiff_residue = np.corrcoef(df[\"uncorrected_lzc\"].astype(\"int\").diff().abs()[1:], df[\"uncorrected_residue\"].astype(\"int\")[:-1])[0,1]\n",
    "        corr_lzc_residue = np.corrcoef(df[\"uncorrected_lzc\"].astype(\"int\"), df[\"uncorrected_residue\"].astype(\"int\"))[0,1]\n",
    "        print(\"{:60} {:5.2f} {:5.2f} {:5.2f} {:5.2f}\".format(item, corr_lzcdiff_ms1, corr_residue_ms1, corr_lzcdiff_residue,corr_lzc_residue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the most likely domain of error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colored_binary(num, center, domain=4, bits=32):\n",
    "    string_repr = np.binary_repr(num,bits)\n",
    "    right,left = min(center + domain, bits), max(center - domain, 0)\n",
    "    restrict = colored(string_repr[:left], 'green')\n",
    "    work_area = colored(string_repr[left:right], 'yellow')\n",
    "    untouched = colored(string_repr[right:],'red')\n",
    "    colored_string_repr = restrict + work_area + untouched\n",
    "    return colored_string_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.frompyfunc(colored_binary, 4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "domain,bits = 4,32\n",
    "df = panel.iloc[1,:,:][[\"uncorrected\",\"corrected\",\"truth\"]].astype(\"int\")\n",
    "df[\"uncorrected_residue\"] = df[\"truth\"] ^ df[\"uncorrected\"]\n",
    "df[\"uncorrected_residue_lzc\"] = lzcu(df[\"uncorrected_residue\"],  bits)\n",
    "tmp = df[[\"uncorrected_residue_lzc\"]].shift(1)\n",
    "tmp.iloc[0] =  0\n",
    "df[\"uncorrected_domain\"] = test(df[[\"uncorrected\"]],tmp,domain, bits)\n",
    "df[\"truth_colored\"] = test(df[[\"truth\"]],tmp, domain, bits)\n",
    "df[\"_s\"] = tmp['uncorrected_residue_lzc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"{:>4} {:>32} {:>32} lzc ctr\".format(\"ix\",\"uncorrected\", \"truth\"))\n",
    "for i in range(330,750):\n",
    "    print(\"{:>4} {:>32} {:>32} {:>3} {:>3}\".format(i,df[\"uncorrected_domain\"][i],df[\"truth_colored\"][i], lzc(df[\"uncorrected\"][i] ^ df[\"truth\"][i]),df['_s'][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most likely domain for improving >90% of the prediction is the range within 4 binary values of the previous LZC. This information gives us the range for a possible bitflip area we need to be careful. Additional information we have is the following:\n",
    "\n",
    "- Value range of the appropiate floating point values\n",
    "- The average case of being either too high or too low\n",
    "- The number of zeros and ones back-to-back for interested area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncorrected_yellows = np.zeros(df.truth.size)\n",
    "truth_yellows = np.zeros(df.truth.size)\n",
    "centers = np.zeros(df.truth.size)\n",
    "rise_tendency = np.zeros(df.truth.size)\n",
    "not_fall_tendency = np.zeros(df.truth.size)\n",
    "\n",
    "# print(\"{:>4} {:>32} {:>32} {:>3} {:>3} ris !fall\".format(\"ix\",\"uncorrected yellow\",\"truth yellow\", \"dif\", \"ctr\"))\n",
    "for i in range(2, df[\"uncorrected\"].size):\n",
    "    selection = 255 << (32 - df[\"_s\"][i] - 4)\n",
    "    move = 32 - df[\"_s\"][i] - 4\n",
    "    uncorrected_yellow = (selection & df[\"uncorrected\"][i]) >> move\n",
    "    truth_yellow = (selection & df[\"truth\"][i]) >> move\n",
    "    center = df['_s'][i]\n",
    "    diff = max(uncorrected_yellow,truth_yellow) - min(uncorrected_yellow,truth_yellow)\n",
    "    rising = df[\"truth\"][i-1] > df[\"truth\"][i-2]\n",
    "    not_falling = df[\"truth\"][i] >= df[\"truth\"][i-1]\n",
    "#     print(\"{:>4} {:>32b} {:>32b} {:>3} {:>3} {} {}\".format(i,uncorrected_yellow,truth_yellow,diff,center,rising,not_falling))\n",
    "    uncorrected_yellows[i] = uncorrected_yellow\n",
    "    truth_yellows[i] = truth_yellow\n",
    "    centers[i] = center\n",
    "    rise_tendency[i] = rising\n",
    "    not_fall_tendency[i] = not_falling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({\"uncorrected_yellows\":uncorrected_yellows.astype(int), \"truth_yellows\":truth_yellows.astype(int),\n",
    "                    \"centers\":centers.astype(int), \"rise_tendency\":rise_tendency.astype(bool), \"not_fall_tendency\":not_fall_tendency.astype(bool)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"adiff\"] = (df2[\"uncorrected_yellows\"]-df2[\"truth_yellows\"]).abs()\n",
    "df2[\"diff\"] = (df2[\"uncorrected_yellows\"]-df2[\"truth_yellows\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
